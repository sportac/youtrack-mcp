{
    "project": "DEMO",
    "summary": "2 - Fix OpenAI API Token Limit Exceedance in Business Knowledge Processor",
    "description": "## **Motivation**\nThe Business Knowledge Processor is failing with BadRequestError when processing large text chunks for embeddings. The error occurs because the system attempts to send 340,632 tokens to the OpenAI API, which exceeds the 300,000 token limit per request for text-embedding-3-small model.\n\n## **Description**\nImplement token limit validation and chunking logic in the embedding service to prevent requests that exceed OpenAI token limits. The current chunk_text function uses a default max_tokens=700 but does not account for the total batch size when multiple chunks are sent together in create_embedding_batch.\n\n## **Acceptance Criteria**\n* Add token counting validation before sending embedding requests\n* Implement batch splitting logic to ensure requests stay under 300,000 token limit\n* Add proper error handling for token limit exceeded scenarios\n* Ensure business knowledge processing completes successfully for large documents\n\n## **DoD**\n* All AC met\n* Code reviewed\n* Deployed\n* Verified in production\n\n## **Dependency**\nNone"
}